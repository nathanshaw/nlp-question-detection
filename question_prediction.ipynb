{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## METHOD 1: Using basic Parse tree created using Stanford's CORE NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pycorenlp import StanfordCoreNLP\n",
    "\n",
    "class isQuestionBasic():\n",
    "    \n",
    "    # Init Constructor\n",
    "    # Initialize StanfordCore NLP local instance on port 9000\n",
    "    def __init__(self):\n",
    "        self.nlp = StanfordCoreNLP('http://localhost:9000')\n",
    "        \n",
    "    # Input: Sentence to be predicted\n",
    "    # Processing: 1. Uses Stanfors NLP's 'annotate' method to create Parse Tree\n",
    "    # 2. Checks for occurence of 'SQ' or 'SBARQ' in the parse tree\n",
    "    # Return: 1 - If sentence is question | 0 - If sentence is not a question\n",
    "    def isQuestion(self, sentence):\n",
    "        if '?' in sentence:\n",
    "            return 1\n",
    "        output = self.nlp.annotate(sentence, properties={\n",
    "            'annotators': 'parse',\n",
    "            'outputFormat': 'json',\n",
    "            'timeout': 1000,\n",
    "        })\n",
    "\n",
    "        if ('SQ' or 'SBARQ') in output['sentences'][0][\"parse\"]:\n",
    "            return 1    \n",
    "        else:\n",
    "            return 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "isQuestionBasic_obj = isQuestionBasic()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Check whether you have started the CoreNLP server e.g.\n$ cd stanford-corenlp-full-2015-12-09/ \n$ java -mx4g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadStatusLine\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    704\u001b[0m     conn,\n\u001b[1;32m    705\u001b[0m     method,\n\u001b[1;32m    706\u001b[0m     url,\n\u001b[1;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    708\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    709\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    711\u001b[0m )\n\u001b[1;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/urllib3/connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m             \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m             \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m             \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m             six\u001b[39m.\u001b[39;49mraise_from(e, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    450\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/urllib3/connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m     httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    445\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m     \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m     \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m     \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.10/3.10.9/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py:1374\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1374\u001b[0m     response\u001b[39m.\u001b[39;49mbegin()\n\u001b[1;32m   1375\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.10/3.10.9/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.10/3.10.9/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py:300\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_conn()\n\u001b[0;32m--> 300\u001b[0m     \u001b[39mraise\u001b[39;00m BadStatusLine(line)\n\u001b[1;32m    302\u001b[0m \u001b[39m# The status code is a three-digit number\u001b[39;00m\n",
      "\u001b[0;31mBadStatusLine\u001b[0m: ÿ\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0001\r\u0000Accept-Encod",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mProtocolError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/requests/adapters.py:489\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunked:\n\u001b[0;32m--> 489\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    490\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    491\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    492\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    493\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    494\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    495\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    496\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    497\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    498\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    499\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    500\u001b[0m     )\n\u001b[1;32m    502\u001b[0m \u001b[39m# Send the request.\u001b[39;00m\n\u001b[1;32m    503\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/urllib3/connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    785\u001b[0m     e \u001b[39m=\u001b[39m ProtocolError(\u001b[39m\"\u001b[39m\u001b[39mConnection aborted.\u001b[39m\u001b[39m\"\u001b[39m, e)\n\u001b[0;32m--> 787\u001b[0m retries \u001b[39m=\u001b[39m retries\u001b[39m.\u001b[39;49mincrement(\n\u001b[1;32m    788\u001b[0m     method, url, error\u001b[39m=\u001b[39;49me, _pool\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m, _stacktrace\u001b[39m=\u001b[39;49msys\u001b[39m.\u001b[39;49mexc_info()[\u001b[39m2\u001b[39;49m]\n\u001b[1;32m    789\u001b[0m )\n\u001b[1;32m    790\u001b[0m retries\u001b[39m.\u001b[39msleep()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/urllib3/util/retry.py:550\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[39mif\u001b[39;00m read \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_method_retryable(method):\n\u001b[0;32m--> 550\u001b[0m     \u001b[39mraise\u001b[39;00m six\u001b[39m.\u001b[39;49mreraise(\u001b[39mtype\u001b[39;49m(error), error, _stacktrace)\n\u001b[1;32m    551\u001b[0m \u001b[39melif\u001b[39;00m read \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/urllib3/packages/six.py:769\u001b[0m, in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    768\u001b[0m \u001b[39mif\u001b[39;00m value\u001b[39m.\u001b[39m__traceback__ \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m tb:\n\u001b[0;32m--> 769\u001b[0m     \u001b[39mraise\u001b[39;00m value\u001b[39m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m    770\u001b[0m \u001b[39mraise\u001b[39;00m value\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    704\u001b[0m     conn,\n\u001b[1;32m    705\u001b[0m     method,\n\u001b[1;32m    706\u001b[0m     url,\n\u001b[1;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    708\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    709\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    711\u001b[0m )\n\u001b[1;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/urllib3/connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m             \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m             \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m             \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m             six\u001b[39m.\u001b[39;49mraise_from(e, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    450\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/urllib3/connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m     httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    445\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m     \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m     \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m     \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.10/3.10.9/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py:1374\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1374\u001b[0m     response\u001b[39m.\u001b[39;49mbegin()\n\u001b[1;32m   1375\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.10/3.10.9/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.10/3.10.9/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py:300\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_conn()\n\u001b[0;32m--> 300\u001b[0m     \u001b[39mraise\u001b[39;00m BadStatusLine(line)\n\u001b[1;32m    302\u001b[0m \u001b[39m# The status code is a three-digit number\u001b[39;00m\n",
      "\u001b[0;31mProtocolError\u001b[0m: ('Connection aborted.', BadStatusLine('ÿ\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x7f\\r\\x00Accept-Encod'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pycorenlp/corenlp.py:19\u001b[0m, in \u001b[0;36mStanfordCoreNLP.annotate\u001b[0;34m(self, text, properties)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 19\u001b[0m     requests\u001b[39m.\u001b[39;49mget(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mserver_url)\n\u001b[1;32m     20\u001b[0m \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mConnectionError:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[39m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39m:rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39;49m\u001b[39mget\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, params\u001b[39m=\u001b[39;49mparams, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/requests/sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    586\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 587\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    589\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/requests/sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    703\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/requests/adapters.py:547\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m--> 547\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(err, request\u001b[39m=\u001b[39mrequest)\n\u001b[1;32m    549\u001b[0m \u001b[39mexcept\u001b[39;00m MaxRetryError \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;31mConnectionError\u001b[0m: ('Connection aborted.', BadStatusLine('ÿ\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x7f\\r\\x00Accept-Encod'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39mqueries-10k-txt\u001b[39m\u001b[39m'\u001b[39m, sep\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mis_question\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39;49m\u001b[39mQUERY\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(isQuestionBasic_obj\u001b[39m.\u001b[39;49misQuestion)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4661\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   4662\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4666\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   4667\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   4668\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4669\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4670\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4769\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4770\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4771\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/apply.py:1123\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[1;32m   1122\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[0;32m-> 1123\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/apply.py:1174\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1172\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1173\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[0;32m-> 1174\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[1;32m   1175\u001b[0m             values,\n\u001b[1;32m   1176\u001b[0m             f,\n\u001b[1;32m   1177\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[1;32m   1178\u001b[0m         )\n\u001b[1;32m   1180\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1181\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1182\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1183\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/_libs/lib.pyx:2924\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[1], line 18\u001b[0m, in \u001b[0;36misQuestionBasic.isQuestion\u001b[0;34m(self, sentence)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m?\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m sentence:\n\u001b[1;32m     17\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m1\u001b[39m\n\u001b[0;32m---> 18\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnlp\u001b[39m.\u001b[39;49mannotate(sentence, properties\u001b[39m=\u001b[39;49m{\n\u001b[1;32m     19\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39mannotators\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39mparse\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     20\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39moutputFormat\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39mjson\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     21\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39mtimeout\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m1000\u001b[39;49m,\n\u001b[1;32m     22\u001b[0m })\n\u001b[1;32m     24\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mSQ\u001b[39m\u001b[39m'\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mSBARQ\u001b[39m\u001b[39m'\u001b[39m) \u001b[39min\u001b[39;00m output[\u001b[39m'\u001b[39m\u001b[39msentences\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mparse\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m     25\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m1\u001b[39m    \n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pycorenlp/corenlp.py:21\u001b[0m, in \u001b[0;36mStanfordCoreNLP.annotate\u001b[0;34m(self, text, properties)\u001b[0m\n\u001b[1;32m     19\u001b[0m     requests\u001b[39m.\u001b[39mget(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mserver_url)\n\u001b[1;32m     20\u001b[0m \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mConnectionError:\n\u001b[0;32m---> 21\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mCheck whether you have started the CoreNLP server e.g.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m     22\u001b[0m     \u001b[39m'\u001b[39m\u001b[39m$ cd stanford-corenlp-full-2015-12-09/ \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m     23\u001b[0m     \u001b[39m'\u001b[39m\u001b[39m$ java -mx4g -cp \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m*\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m edu.stanford.nlp.pipeline.StanfordCoreNLPServer\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     25\u001b[0m data \u001b[39m=\u001b[39m text\u001b[39m.\u001b[39mencode()\n\u001b[1;32m     26\u001b[0m r \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mpost(\n\u001b[1;32m     27\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mserver_url, params\u001b[39m=\u001b[39m{\n\u001b[1;32m     28\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mproperties\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mstr\u001b[39m(properties)\n\u001b[1;32m     29\u001b[0m     }, data\u001b[39m=\u001b[39mdata, headers\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mConnection\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mclose\u001b[39m\u001b[39m'\u001b[39m})\n",
      "\u001b[0;31mException\u001b[0m: Check whether you have started the CoreNLP server e.g.\n$ cd stanford-corenlp-full-2015-12-09/ \n$ java -mx4g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('queries-10k-txt', sep='\\t')\n",
    "df['is_question'] = df['QUERY'].apply(isQuestionBasic_obj.isQuestion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9332\n",
       "1     668\n",
       "Name: is_question, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_question'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## METHOD 2: DETECTION USING NLTK CLASSIFICATION TECHNIQUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('nps_chat')\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk.corpus\n",
    "from nltk.corpus import nps_chat\n",
    "import pandas as pd\n",
    "\n",
    "class IsQuestion():\n",
    "    \n",
    "    # Init constructor\n",
    "    def __init__(self):\n",
    "        posts = self.__get_posts()\n",
    "        feature_set = self.__get_feature_set(posts)\n",
    "        self.classifier = self.__perform_classification(feature_set)\n",
    "        \n",
    "    # Method (Private): __get_posts\n",
    "    # Input: None\n",
    "    # Output: Posts (Text) from NLTK's nps_chat package\n",
    "    def __get_posts(self):\n",
    "        return nltk.corpus.nps_chat.xml_posts()\n",
    "    \n",
    "    # Method (Private): __get_feature_set\n",
    "    # Input: Posts from NLTK's nps_chat package\n",
    "    # Processing: 1. preserve alpha numeric characters, whitespace, apostrophe\n",
    "    # 2. Tokenize sentences using NLTK's word_tokenize\n",
    "    # 3. Create a dictionary of list of tuples for each post where tuples index 0 is the dictionary of words occuring in the sentence and index 1 is the class as received from nps_chat package \n",
    "    # Return: List of tuples for each post\n",
    "    def __get_feature_set(self, posts):\n",
    "        feature_list = []\n",
    "        for post in posts:\n",
    "            post_text = post.text            \n",
    "            features = {}\n",
    "            words = nltk.word_tokenize(post_text)\n",
    "            for word in words:\n",
    "                features['contains({})'.format(word.lower())] = True\n",
    "            feature_list.append((features, post.get('class')))\n",
    "        return feature_list\n",
    "    \n",
    "    # Method (Private): __perform_classification\n",
    "    # Input: List of tuples for each post\n",
    "    # Processing: 1. Divide data into 80% training and 10% testing sets\n",
    "    # 2. Use NLTK's Multinomial Naive Bayes to perform classifcation\n",
    "    # 3. Print the Accuracy of the model\n",
    "    # Return: Classifier object\n",
    "    def __perform_classification(self, feature_set):\n",
    "        training_size = int(len(feature_set) * 0.1)\n",
    "        train_set, test_set = feature_set[training_size:], feature_set[:training_size]\n",
    "        classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "        print('Accuracy is : ', nltk.classify.accuracy(classifier, test_set))\n",
    "        return classifier\n",
    "        \n",
    "    # Method (private): __get_question_words_set\n",
    "    # Input: None\n",
    "    # Return: Set of commonly occuring words in questions\n",
    "    def __get_question_words_set(self):\n",
    "        question_word_list = ['what', 'where', 'when','how','why','did','do','does','have','has','am','is','are','can','could','may','would','will','should'\n",
    "\"didn't\",\"doesn't\",\"haven't\",\"isn't\",\"aren't\",\"can't\",\"couldn't\",\"wouldn't\",\"won't\",\"shouldn't\",'?']\n",
    "        return set(question_word_list)        \n",
    "    \n",
    "    # Method (Public): predict_question\n",
    "    # Input: Sentence to be predicted\n",
    "    # Return: 1 - If sentence is question | 0 - If sentence is not question\n",
    "    def predict_question(self, text):\n",
    "        words = nltk.word_tokenize(text.lower())        \n",
    "        if self.__get_question_words_set().intersection(words) == False:\n",
    "            return 0\n",
    "        if '?' in text:\n",
    "            return 1\n",
    "        \n",
    "        features = {}\n",
    "        for word in words:\n",
    "            features['contains({})'.format(word.lower())] = True            \n",
    "        \n",
    "        prediction_result = self.classifier.classify(features)\n",
    "        if prediction_result == 'whQuestion' or prediction_result == 'ynQuestion':\n",
    "            return 1\n",
    "        return 0\n",
    "    \n",
    "    # Method (Public): predict_question_type\n",
    "    # Input: Sentence to be predicted\n",
    "    # Return: 'WH' - If question is WH question | 'YN' - If sentence is Yes/NO question | 'unknown' - If unknown question type\n",
    "    def predict_question_type(self, text):\n",
    "        words = nltk.word_tokenize(text.lower())                \n",
    "        features = {}\n",
    "        for word in words:\n",
    "            features['contains({})'.format(word.lower())] = True            \n",
    "        \n",
    "        prediction_result = self.classifier.classify(features)\n",
    "        if prediction_result == 'whQuestion':\n",
    "            return 'WH'\n",
    "        elif prediction_result == 'ynQuestion':\n",
    "            return 'YN'\n",
    "        else:\n",
    "            return 'unknown'\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is :  0.6685606060606061\n"
     ]
    }
   ],
   "source": [
    "isQ = IsQuestion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test sample sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isQ.predict_question('what is this')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WH'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isQ.predict_question_type('what is this')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv('queries-10k-txt', sep='\\t')\n",
    "df_1['is_question'] = df_1['QUERY'].apply(isQ.predict_question)\n",
    "df_1['question_type'] = df_1[df_1['is_question'] == 1]['QUERY'].apply(isQ.predict_question_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    8799\n",
       "1    1201\n",
       "Name: is_question, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1['is_question'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WH    944\n",
       "YN    257\n",
       "Name: question_type, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1['question_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## METHOD 3: DETECTION USING ADVANCED CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "class IsQuestionAdvanced():\n",
    "    \n",
    "    # Init constructor\n",
    "    # Input: Type of classification: 'MNB' - Multinomial Naive Bayes | 'SVM' - Support Vector Machine\n",
    "    def __init__(self, classification_type):\n",
    "        self.classification_type = classification_type\n",
    "        df = self.__get_data()\n",
    "        df = self.__clean_data(df)\n",
    "        df = self.__label_encode(df)\n",
    "        vectorizer_classifier = self.__create_classifier(df, self.classification_type)\n",
    "        if vectorizer_classifier is not None:\n",
    "            self.vectorizer = vectorizer_classifier['vectorizer']\n",
    "            self.classifier = vectorizer_classifier['classifier']        \n",
    "        \n",
    "    # Method (Private):  __clean_data\n",
    "    # Input: Raw input dataframe\n",
    "    # Processing: 1. Rename column \n",
    "    # 2. lowercase text\n",
    "    # 3. preserve alpha numeric characters, whitespace, apostrophe\n",
    "    # 4. filter dataframe with questiin types - what, who, when, affirmation, unknown\n",
    "    # Return: Processed filtered dataframe\n",
    "    def __clean_data(self, df):\n",
    "        df.rename(columns={0: 'text', 1: 'type'}, inplace=True)\n",
    "        df['type'] = df['type'].str.strip()\n",
    "        df['text'] = df['text'].apply(lambda x: x.lower())\n",
    "        df['text'] = df['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s\\']','',x)))\n",
    "        return df[(df['type'] == 'what') | (df['type'] == 'who') | (df['type'] == 'when') | (df['type'] == 'unknown') | (df['type'] == 'affirmation')]\n",
    "    \n",
    "\n",
    "    # Method (Private): __label_encode\n",
    "    # Input: Processed dataframe\n",
    "    # Processing: Use label encoding to convert text label to integer label and add it to a new column\n",
    "    # Return: Processed dataframe with label encoding column\n",
    "    def __label_encode(self, df):\n",
    "        self.le = preprocessing.LabelEncoder()\n",
    "        self.le.fit(df['type'])\n",
    "        df['label'] = list(self.le.transform(df['type']))\n",
    "        return df\n",
    "    \n",
    "    # Method (Private): __create_classifier\n",
    "    # Input: 1. Processed dataframe 2. Type of classification\n",
    "    # Processing: 1. Perform TFIDF Vectorization\n",
    "    # 2. Appy fit_tranform using TFIDF on text column\n",
    "    # 3. Split data into 70% training and 30% testing\n",
    "    # 4. Perform Multinomial Naive Bayes OR SVM classifcation based on input provided\n",
    "    # 5. Peform prediction for both classification techniques on test data\n",
    "    # 6. Show confusion matrix and accuracy\n",
    "    # Return: Dict - TFIDF Vetctorizer, Classifier    \n",
    "    def __create_classifier(self, df, classification_type):\n",
    "        v = TfidfVectorizer(analyzer='word',lowercase=True)\n",
    "        X = v.fit_transform(df['text'])\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, df['label'], test_size=0.30)\n",
    "        if classification_type == 'MNB':\n",
    "            clf = MultinomialNB()\n",
    "            clf.fit(X_train,y_train)\n",
    "            preds = clf.predict(X_test)\n",
    "            print(classification_report(preds,y_test))\n",
    "            print('Accuracy is: ', clf.score(X_test,y_test))\n",
    "            return {'vectorizer': v, 'classifier': clf}\n",
    "        elif classification_type == 'SVM':\n",
    "            clf_svm = SVC(kernel='linear')\n",
    "            clf_svm.fit(X_train,y_train)\n",
    "            preds = clf_svm.predict(X_test)\n",
    "            preds = print(classification_report(preds,y_test))\n",
    "            print('Accuracy is: ', clf_svm.score(X_test,y_test))\n",
    "            return {'vectorizer': v, 'classifier': clf_svm}\n",
    "        else:\n",
    "            print(\"Wrong classification type: \\n Type 'MNB' - Multinomial Naive Bayes \\n Type 'SVM' - Support Vector Machine\")    \n",
    "            \n",
    "\n",
    "    # Method (Private): __get_data\n",
    "    # Processing: Get the sample input data used to create traning, test, vectorizer, classifier data\n",
    "    # Return: Pandas dataframe\n",
    "    def __get_data(self):\n",
    "        return pd.read_csv('sample.txt', sep=',,,', header=None)\n",
    "    \n",
    "    # Method (Public): predict\n",
    "    # Input: An unknown new sentence\n",
    "    # Return: Prediction - Typpe of question 'what', 'when', 'who'\n",
    "    def predict(self, sentence):\n",
    "        ex = self.vectorizer.transform([sentence])\n",
    "        return list(self.le.inverse_transform(self.classifier.predict(ex)))[0]                \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:86: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94        31\n",
      "           1       0.96      0.95      0.95        76\n",
      "           2       0.97      0.97      0.97       196\n",
      "           3       0.90      0.84      0.87        32\n",
      "           4       0.99      0.99      0.99       110\n",
      "\n",
      "    accuracy                           0.96       445\n",
      "   macro avg       0.94      0.95      0.95       445\n",
      "weighted avg       0.96      0.96      0.96       445\n",
      "\n",
      "Accuracy is:  0.9640449438202248\n"
     ]
    }
   ],
   "source": [
    "# Model created using SVM\n",
    "obj = IsQuestionAdvanced('SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'when'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.predict('what time are you going there')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run model on questions classified by method 1 <br> df is created by method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = df[df['is_question'] == 1].copy()\n",
    "df_2['question_type'] = df_2['QUERY'].apply(obj.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "what       405\n",
       "unknown    193\n",
       "who         52\n",
       "when        18\n",
       "Name: question_type, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2['question_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run model on questions classified by method 2 <br> df_1 is created by method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = df_1[df_1['is_question'] == 1].copy()\n",
    "df_3['question_type'] = df_3['QUERY'].apply(obj.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unknown        593\n",
       "what           544\n",
       "who             50\n",
       "when             8\n",
       "affirmation      6\n",
       "Name: question_type, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3['question_type'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
